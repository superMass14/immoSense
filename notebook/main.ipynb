{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966e907-8d87-4db8-a47c-ce64990c377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf7526",
   "metadata": {},
   "source": [
    "## Feature engineering + data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyFactors = [\n",
    "\n",
    "          # Identifiant (à conserver pour référence)\n",
    "        'Id',\n",
    "        \n",
    "        # Variables structurelles essentielles\n",
    "        'OverallQual',      # Qualité générale\n",
    "        'OverallCond',      # Condition générale\n",
    "        'YearBuilt',        # Année de construction \n",
    "        'YearRemodAdd',     # Année de rénovation\n",
    "        \n",
    "        # Surfaces\n",
    "        'GrLivArea',        # Surface habitable\n",
    "        'TotalBsmtSF',      # Surface totale du sous-sol\n",
    "        'LotArea',          # Surface du terrain\n",
    "        \n",
    "        # Garage et extérieur\n",
    "        'GarageArea',       # Surface du garage\n",
    "        'GarageCars',       # Capacité du garage en voitures\n",
    "        'GarageYrBlt',      # Année de construction du garage\n",
    "        'GarageType',       # Type de garage\n",
    "        'GarageFinish',     # Finition du garage\n",
    "        \n",
    "        # Pièces et salles de bain\n",
    "        'FullBath',         # Salles de bain complètes\n",
    "        'HalfBath',         # Demi-salles de bain\n",
    "        'BedroomAbvGr',     # Chambres au-dessus du sol\n",
    "        'KitchenAbvGr',     # Cuisines au-dessus du sol\n",
    "     \n",
    "        # Qualité\n",
    "        'KitchenQual',      # Qualité de la cuisine\n",
    "        'ExterQual',        # Qualité extérieure\n",
    "        'ExterCond',        # Condition extérieure\n",
    "        'BsmtCond',         # Condition du sous-sol\n",
    "        'HeatingQC',        # Qualité du chauffage\n",
    "        \n",
    "        # Localisation\n",
    "        'Neighborhood',     # Quartier\n",
    "        'MSZoning',         # Zonage\n",
    "        \n",
    "        # Caractéristiques additionnelles de valeur\n",
    "        'Fireplaces',       # Nombre de cheminées\n",
    "        'FireplaceQu',      # Qualité des cheminées\n",
    "        'WoodDeckSF',       # Surface de la terrasse en bois\n",
    "        'OpenPorchSF',      # Surface du porche ouvert\n",
    "        'Foundation',       # Type de fondation\n",
    "        'CentralAir',       # Climatisation centrale\n",
    "        \n",
    "        # Variables de vente (pour l'entraînement)\n",
    "\n",
    "        'SaleType',         # Type de vente\n",
    "        'SaleCondition',    # Condition de vente\n",
    "        'MiscFeature',        # Commonditer qui ne figure pas details\n",
    "        \n",
    "        # target\n",
    "        'SalePrice'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e379a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()[keyFactors]\n",
    "df.set_index(\"Id\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98af60",
   "metadata": {},
   "source": [
    "### Let's add some features !\n",
    "we have some redundants features storing the same values and sharing the information. Those columns can be merged by selected the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9526c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Exterior1st', 'Exterior2nd', 'Condition1', 'Condition2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Exterior'] = data['Exterior2nd'].values\n",
    "df.loc[:,'Condition'] = data['Condition2'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd232564",
   "metadata": {},
   "source": [
    "We can also add the house's lifespan from the build year till the purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61392b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lifespan\"] = np.int64(data[\"YrSold\"] - data[\"YearBuilt\"])\n",
    "df.fillna({\"LifeSpan\": 0}, inplace=True) # there is no duration when the result is NA\n",
    "#####\n",
    "df = df[df.columns.sort_values()] # sorts the columns in alphabetic order\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f62c4c",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates and checking missing values\n",
    "df.drop_duplicates(inplace=True)\n",
    "a = df.isna().sum()\n",
    "a[a>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d261a0",
   "metadata": {},
   "source": [
    "samples having **NA** values means that that feature does not exist for that house. these values won't be dropped but will be replaced by \"empty\" and encoded during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250dccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replaces the NA with \"Empty\"\n",
    "def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    temp = df.copy()\n",
    "    cols_with_empty_values = a[a>0].index\n",
    "    for c in cols_with_empty_values:\n",
    "            temp[c] = temp[c].fillna(\"Empty\")\n",
    "    return temp\n",
    "\n",
    "df = fill_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check values type for each sample\n",
    "def check(df: pd.DataFrame):\n",
    "    temp = df.dropna(axis=0)\n",
    "    print(\"start cheking ...\")\n",
    "    for col in temp.columns:\n",
    "        if temp[col].dtype == np.int64:\n",
    "            try:\n",
    "                np.int64(temp[col])\n",
    "            except Exception as e:\n",
    "                print(f\"'{col.capitalize()}' feature should have int64 type for all samples\")\n",
    "        elif temp[col].dtype == np.float64:\n",
    "            try:\n",
    "                np.float64(temp[col])\n",
    "            except Exception as e:\n",
    "                print(f\"'{col.capitalize()}' feature should have float64 type for all samples\")\n",
    "        else :\n",
    "            try:\n",
    "                np.object_(temp[col])\n",
    "            except Exception as e:\n",
    "                print(f\"'{col.capitalize()}' feature should have object type for all samples\")\n",
    "    print(\"All columns are checked \")\n",
    "\n",
    "check(df)\n",
    "print(f\"we have {df.shape[0]} samples and {df.shape[1]} features with the houses id set as index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d16138",
   "metadata": {},
   "source": [
    "let's repeat the sama data manipulation with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c414f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing data\n",
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "df_test = test_data.copy()[keyFactors[:-1]]\n",
    "df_test.set_index(\"Id\", inplace=True)\n",
    "\n",
    "## feature engineering\n",
    "df_test.loc[:,'Exterior'] = test_data['Exterior2nd'].values\n",
    "df_test.loc[:,'Condition'] = test_data['Condition2'].values\n",
    "df_test.loc[:,\"Lifespan\"] = np.int64(test_data[\"YrSold\"] - test_data[\"YearBuilt\"])\n",
    "df_test.fillna({\"LifeSpan\": 0}, inplace=True) # there is no duration when the result is NA\n",
    "df_test = df_test[df_test.columns.sort_values()] # sorts the columns in alphabetic order\n",
    "\n",
    "# removing duplicates and checking missing values\n",
    "df_test.drop_duplicates(inplace=True)\n",
    "df_test = fill_missing_values(df_test)\n",
    "check(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b09c6",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "we will display the insights and highlight how the selected features are relevant for the sale price prediction.\n",
    "features are categorized into nine(9) parts:\n",
    "* **Essential structural variables** : *'OverallQual'*, *'OverallCond'*, *'YearBuilt'*, *'YearRemodAdd'*\n",
    "* **Surfaces** : *GrLivArea*, *TotalBsmtSF*, *LotArea*  \n",
    "* **Garage and Exterior** : *GarageArea*, *GarageCars*, *GarageYrBlt*, *GarageType*, *GarageFinish*  \n",
    "* **Rooms and Bathrooms** : *FullBath*, *HalfBath*, *BedroomAbvGr*, *KitchenAbvGr*  \n",
    "* **Quality** : *KitchenQual*, *ExterQual*, *ExterCond*, *BsmtCond*, *HeatingQC*  \n",
    "* **Location** : *Neighborhood*, *MSZoning*  \n",
    "* **Additional Value Features** : *Fireplaces*, *FireplaceQu*, *WoodDeckSF*, *OpenPorchSF*, *Foundation*, *CentralAir*  \n",
    "* **Sales Variables (for training)** : *SaleType*, *SaleCondition*, *MiscFeature*  \n",
    "* **Created features** : *Exterior*, *LifeSpan*, *Condition*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648230f",
   "metadata": {},
   "source": [
    "## ImmoSense model conception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba5e06",
   "metadata": {},
   "source": [
    "first, let's cast our continuous or categorical data into dummy version (true or false state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.copy()[\"SalePrice\"]\n",
    "df.drop(\"SalePrice\", axis=1, inplace=True)\n",
    "dummy = pd.get_dummies(df)\n",
    "dummy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a94516",
   "metadata": {},
   "source": [
    "let's split it inton train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test,y_train, y_test = train_test_split(dummy, target ,test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb1e10",
   "metadata": {},
   "source": [
    "let's pick the best model for our study case between:\n",
    "* **Linear Regression**\n",
    "* **SVR**\n",
    "* **Ridge**\n",
    "* **Nearest neighbors regression**\n",
    "* **Decision trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "models = {\n",
    "    \"Linear_regression\": LinearRegression(),\n",
    "    \"KNR\": KNeighborsRegressor(),\n",
    "    \"SVR\": SVR(kernel=\"linear\"),\n",
    "    \"Ridge\": Ridge(alpha=0.5),\n",
    "    \"Decision\": DecisionTreeRegressor()\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "def check_perf(model_list: dict, x_train, y_train, x_test, y_test) -> pd.DataFrame:\n",
    "    rmse_tab, mae_tab, r_2_tab, score_tab = [], [], [], []\n",
    "    \n",
    "    for mod in model_list.values():\n",
    "        mod.fit(x_train, y_train) # training thre model with training data\n",
    "        y_pred = mod.predict(x_test) # prediction with samples splitted for test\n",
    "        \n",
    "        ## --- some metrics to evaluate model's prediction\n",
    "        rmse_tab.append(round(root_mean_squared_error(y_test, y_pred),2)) \n",
    "        mae_tab.append(round(mean_absolute_error(y_test, y_pred), 2)) \n",
    "        r_2_tab.append(round(r2_score(y_test, y_pred),3))\n",
    "        score_tab.append(f'{mod.score(x_train, y_train)*100}%') # training score\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "                        \"RMSE\": rmse_tab,\n",
    "                        \"Mae\": mae_tab,\n",
    "                        \"R2\": r_2_tab,\n",
    "                        \"Scores\": score_tab\n",
    "                        }, index=model_list.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21916311",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_perf(models, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411647a2",
   "metadata": {},
   "source": [
    "if we compare the metrics above we notice that the **Ridge_regression model** has a lower **mean error** with a quite acceptable **training score**. So **ImmoSense** model will be : **\"Ridge\"**. for better result, let's choose the best parameter for **ImmoSense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f805af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "immoSense_test = Ridge()\n",
    "params = {\"alpha\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "gd = GridSearchCV(immoSense_test, param_grid=params, cv=5, n_jobs=-1, scoring=\"r2\")\n",
    "gd.fit(x_train, y_train)\n",
    "print(f\"the best alpha parameter is {gd.best_params_} with a best score trianing score of {gd.best_score_*100:.2f}% \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7676ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training ImmoSense model with best estimator and best params\n",
    "ImmoSense = Ridge(1.0)\n",
    "ImmoSense.fit(x_train, y_train)\n",
    "print(\"ImmoSense well trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6aecf6",
   "metadata": {},
   "source": [
    "## Final prediction\n",
    "let's predict prices with the test_set file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.ffill(inplace=True)\n",
    "dummy_test = pd.get_dummies(df_test)\n",
    "dummy_test = dummy_test.reindex(columns=dummy.columns, fill_value=0)\n",
    "prices = ImmoSense.predict(dummy_test)\n",
    "pd.DataFrame({\"SalePrice\": np.int64(prices)}, index=dummy_test.index).to_csv(\"../data/submission.csv\",sep=\",\",header=True)\n",
    "print(\"Submission file generated successfully !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
